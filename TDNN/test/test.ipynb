{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33c15c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from utils.helpers import check_cuda, ModelSaver\n",
    "from utils.prepare_data import prepare_mfcc, create_audio_path_and_text, read_phonemes, prepare_input_data, phonemes_to_ids\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36701837",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualTDNNBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_size, dilation=1, dropout=None,bypass_scale = 0.5):\n",
    "        super().__init__()\n",
    "        self.tdnn1 = TDNNBlock(channels, channels, kernel_size, dilation, dropout)\n",
    "        self.tdnn2 = TDNNBlock(channels, channels, kernel_size, dilation, dropout)\n",
    "        self.bypass_scale = bypass_scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.tdnn1(x)\n",
    "        out = self.tdnn2(out)\n",
    "        return out + residual * self.bypass_scale\n",
    "\n",
    "class TDNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, dropout=None, activation = True):\n",
    "        super().__init__()\n",
    "        padding = dilation * (kernel_size // 2)\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size,\n",
    "                            dilation=dilation, padding=padding)\n",
    "        self.ln = nn.LayerNorm(out_channels)\n",
    "        self.relu = nn.ReLU() if activation is True else nn.Identity()# wer 17\n",
    "        self.dropout = nn.Dropout1d(dropout) if dropout is not None else nn.Identity()\n",
    "\n",
    "    def forward(self, x):  # x: [B, C_in, T]\n",
    "        out = self.conv(x)           # [B, C_out, T]\n",
    "        out = out.transpose(1,2)\n",
    "        out = self.ln(out)\n",
    "        out = out.transpose(1,2)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "class TDNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TDNN, self).__init__()\n",
    "        self.tdnn1 = TDNNBlock(input_dim, 400, kernel_size=7,dilation=1)\n",
    "        self.tdnn2 = TDNNBlock(400, 400, kernel_size=5, dilation=2,dropout=0.2)\n",
    "        self.tdnn3 = TDNNBlock(400, 400, kernel_size=5, dilation=3,dropout=0.3)\n",
    "        self.res1 = ResidualTDNNBlock(400, kernel_size=3, dilation=2)\n",
    "        self.res2 = ResidualTDNNBlock(400, kernel_size=3,dilation=1)\n",
    "        self.res3 = ResidualTDNNBlock(400, kernel_size=3,dilation=1)\n",
    "        self.tdnn4 = TDNNBlock(400, 300, kernel_size=1,dropout=0.3)\n",
    "        self.tdnn5 = TDNNBlock(300, 300, kernel_size=1,dropout=0.4)\n",
    "        self.tdnn6 = TDNNBlock(300, output_dim, kernel_size=1, activation = False)\n",
    " \n",
    "    def forward(self, x):  # x: [B, T, F]\n",
    "        x = x.transpose(1, 2)  # [B, F, T]\n",
    "        x = self.tdnn1(x)\n",
    "        x = self.tdnn2(x)\n",
    "        x = self.tdnn3(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.res2(x)\n",
    "        x = self.res3(x)\n",
    "        x = self.tdnn4(x)\n",
    "        x = self.tdnn5(x)\n",
    "        x = self.tdnn6(x)\n",
    "        x = x.transpose(1, 2)  # [B, T, F]\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(\"test.flac\", sr=16000)  \n",
    "mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "mfcc = (mfcc - np.mean(mfcc, axis=1, keepdims=True)) / np.std(mfcc, axis=1, keepdims=True)\n",
    "np.save(\"test.npy\", mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "991462b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TDNN(\n",
       "  (tdnn1): TDNNBlock(\n",
       "    (conv): Conv1d(40, 400, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (ln): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Identity()\n",
       "  )\n",
       "  (tdnn2): TDNNBlock(\n",
       "    (conv): Conv1d(400, 400, kernel_size=(5,), stride=(1,), padding=(4,), dilation=(2,))\n",
       "    (ln): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout1d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (tdnn3): TDNNBlock(\n",
       "    (conv): Conv1d(400, 400, kernel_size=(5,), stride=(1,), padding=(6,), dilation=(3,))\n",
       "    (ln): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout1d(p=0.3, inplace=False)\n",
       "  )\n",
       "  (res1): ResidualTDNNBlock(\n",
       "    (tdnn1): TDNNBlock(\n",
       "      (conv): Conv1d(400, 400, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "      (ln): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (tdnn2): TDNNBlock(\n",
       "      (conv): Conv1d(400, 400, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "      (ln): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "  )\n",
       "  (res2): ResidualTDNNBlock(\n",
       "    (tdnn1): TDNNBlock(\n",
       "      (conv): Conv1d(400, 400, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (ln): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (tdnn2): TDNNBlock(\n",
       "      (conv): Conv1d(400, 400, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (ln): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "  )\n",
       "  (res3): ResidualTDNNBlock(\n",
       "    (tdnn1): TDNNBlock(\n",
       "      (conv): Conv1d(400, 400, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (ln): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "    (tdnn2): TDNNBlock(\n",
       "      (conv): Conv1d(400, 400, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (ln): LayerNorm((400,), eps=1e-05, elementwise_affine=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Identity()\n",
       "    )\n",
       "  )\n",
       "  (tdnn4): TDNNBlock(\n",
       "    (conv): Conv1d(400, 300, kernel_size=(1,), stride=(1,))\n",
       "    (ln): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout1d(p=0.3, inplace=False)\n",
       "  )\n",
       "  (tdnn5): TDNNBlock(\n",
       "    (conv): Conv1d(300, 300, kernel_size=(1,), stride=(1,))\n",
       "    (ln): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    (relu): ReLU()\n",
       "    (dropout): Dropout1d(p=0.4, inplace=False)\n",
       "  )\n",
       "  (tdnn6): TDNNBlock(\n",
       "    (conv): Conv1d(300, 87, kernel_size=(1,), stride=(1,))\n",
       "    (ln): LayerNorm((87,), eps=1e-05, elementwise_affine=True)\n",
       "    (relu): Identity()\n",
       "    (dropout): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = check_cuda()\n",
    "saver = ModelSaver()\n",
    "model = TDNN(40, 87)\n",
    "point_model = saver.load_state(model=model,path = \"models/2025-07-23_00-06/point_final_ep-69\")\n",
    "model = point_model \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27dbc642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 81)\n",
      "torch.Size([1, 40, 81])\n",
      "['S', 'F', 'AW1', 'ER0', 'ER0', 'F', 'Y', 'UW1']\n"
     ]
    }
   ],
   "source": [
    "phonemes = read_phonemes(\"../utils/phonemes.txt\")\n",
    "phoneme2id,id2phoneme = phonemes_to_ids(phonemes)\n",
    "\n",
    "def ctc_greedy_decode(log_probs, blank=0):\n",
    "    preds = log_probs.argmax(dim=-1).transpose(0, 1)  # [batch, time]\n",
    "\n",
    "    decoded_batch = []\n",
    "    for pred in preds:\n",
    "        prev = None\n",
    "        decoded = []\n",
    "        for p in pred.cpu().numpy():\n",
    "            if p != blank and p != prev:\n",
    "                decoded.append(p)\n",
    "            prev = p\n",
    "        decoded_batch.append(decoded)\n",
    "    return decoded_batch\n",
    "\n",
    "with torch.no_grad():\n",
    "    features = np.load(\"test.npy\")\n",
    "    print(features.shape)\n",
    "    features = torch.from_numpy(features).float().unsqueeze(0)\n",
    "    print(features.shape)\n",
    "    features = features.transpose(1, 2)\n",
    "    output = model(features)\n",
    "    log_probs = output.transpose(0, 1)\n",
    "    preds = ctc_greedy_decode(log_probs, blank=0)\n",
    "    for seq in preds:\n",
    "        print([id2phoneme[p] for p in seq])\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
